{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56H893l5yxgL"
   },
   "source": [
    "# S3. Exploratory Data Analysis: PV generation forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPI5Drb4yxgL"
   },
   "source": [
    "**Exploratory Data Analysis** (EDA) in data science is the process of analyzing datasets to summarize their main characteristics, often using visual methods. It’s an initial step used to understand the structure of the data, detect patterns, spot anomalies, and check assumptions before moving to more complex modeling. EDA helps data scientists gain insights and inform decision-making about how to treat the data in subsequent steps of analysis or machine learning.\n",
    "\n",
    "Key components of EDA include:\n",
    "\n",
    "* **Data Cleaning**: Handling missing data, removing duplicates, and correcting inconsistencies.\n",
    "* **Descriptive Statistics**: Calculating basic statistics like mean, median, variance, and standard deviation to summarize data.\n",
    "* **Data Visualization**: Using plots such as histograms, scatter plots, box plots, and correlation matrices to visually explore relationships, distributions, and trends.\n",
    "* **Outlier Detection**: Identifying unusual data points that may skew the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGWcE5kpyxgL"
   },
   "source": [
    "# How to create a Supervised Learning model from scratch?\n",
    "\n",
    "In this class we will focus on the initial part of this process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlhxTLfjyxgM"
   },
   "source": [
    "<img src=\"Figures/ml-process-eda-v2.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXkjedn-yxgM"
   },
   "source": [
    "## **Import libraries and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "texHLK1UyxgM"
   },
   "outputs": [],
   "source": [
    "import sklearn  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Cargamos el conjunto de datos de entrada\n",
    "dataset = pd.read_csv('data/EJ1-data-pv.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo54acElyxgN"
   },
   "source": [
    "## **Step 1:Understand data**\n",
    "\n",
    "<img src=\"Figures/step1-understand-data-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "### Descriptive statistics\n",
    "\n",
    "It is necessary to visualize and understand the data with which we are going to work, as well as to know its characteristics. \n",
    "\n",
    "1. How much data is there? How many attributes are there in the data?  \n",
    "2. What do they mean?\n",
    "3. Is there any missing data?\n",
    "4. Statistical summary of the input data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D7OC69JyxgN"
   },
   "source": [
    "**1. How much data is there? How many attributes are there in the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rI0RfeMQyxgN"
   },
   "outputs": [],
   "source": [
    "# Filas x columnas de los datos\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtXKDnGDyxgN"
   },
   "source": [
    "**2. What do they mean?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFzVcHqUyxgO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Observa las primeras 5 filas de datos\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wq3egJm_yxgO"
   },
   "outputs": [],
   "source": [
    "#  Data format (int/float/object)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir7dYEWxyxgO"
   },
   "outputs": [],
   "source": [
    "# Convert localhour column in a datetime type\n",
    "dataset['localhour'] = pd.to_datetime(dataset['localhour'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, run the Data format again (int/float/object)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5SNhVa5yxgO"
   },
   "source": [
    "**3. Is there any missing data?** A check is made to see if any data is missing, and if so, the count of empty cells in each attribute is performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOevzp2IyxgO"
   },
   "outputs": [],
   "source": [
    "# Check if any data is missing and in which attribute\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh2Lkz6LyxgO"
   },
   "source": [
    "**4. Statistical summary of the input data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYPRCb4VyxgP"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can create new features from the raw dataset\n",
    "\n",
    "\n",
    "`datetime.dt` provides a wide range of methods to extract specific date and time components from a `datetime object`. Below is a list of the commonly used attributes and methods.\n",
    "\n",
    "\n",
    "* `dataset['year'] = dataset['localhour'].dt.year`\n",
    "* `dataset['month'] = dataset['localhour'].dt.month`\n",
    "* `dataset['day'] = dataset['localhour'].dt.day`\n",
    "* `dataset['hour'] = dataset['localhour'].dt.hour`\n",
    "* `dataset['minute'] = dataset['localhour'].dt.minute`\n",
    "* `dataset['week'] = dataset['localhour'].dt.week`\n",
    "* `dataset['day_of_week'] = dataset['localhour'].dt.dayofweek`\n",
    "* `dataset['day_name'] = dataset['localhour'].dt.day_name()`\n",
    "\n",
    "For more information, check this website https://docs.python.org/3/library/datetime.html#datetime.date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9qpjl5jyxgP"
   },
   "outputs": [],
   "source": [
    "# Add hour\n",
    "dataset['hour'] = dataset['localhour'].dt.hour\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ccffcc; padding:10px; border-radius:5px;\">\n",
    "\n",
    "### <span style=\"color:blue\">Exercise 1</span>\n",
    "\n",
    "Add two new features: month  and day\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write you code\n",
    "#  Add month column and day column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMLw7UqkyxgP"
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"Figures/step1-understand-data-2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX7kRTjSyxgP"
   },
   "source": [
    "# Histogram\n",
    "\n",
    "A histogram is a graphical representation of the distribution of numerical data in data science. It provides a visual way to understand how frequently each range of values (or bins) occurs in a dataset.\n",
    "\n",
    "* The **x-axis** of a histogram is divided into intervals called bins or buckets. Each bin represents a range of values.\n",
    "* The **y-axis** shows the frequency or count of data points that fall within each bin. This indicates how many observations fall into each range of values.\n",
    "\n",
    "* Histograms help identify the **shape of the data distribution**, such as whether it is **normal (bell-shaped), skewed, uniform, or bimodal** (having two peaks).\n",
    "* A histogram can also help to visualize any **outliers** in the data—values that fall far outside the range of the other observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Examples of data shapes using histograms\n",
    " \n",
    " Histograms can have different shapes depending on the data they are representing.\n",
    "[Source: LabXchange](https://www.labxchange.org/library/items/lb:LabXchange:10d3270e:html:1)\n",
    " \n",
    " <img src=\"Figures/type-histograms.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7pOmcPfyxgP"
   },
   "outputs": [],
   "source": [
    "# we can plot the histogram in Pandas Dataframe directly using dataframe.hist()\n",
    "\n",
    "histogram = dataset.hist(xlabelsize=10, ylabelsize=10, bins=100, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Figures/type-histograms-2.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density plots\n",
    "\n",
    "A density plot is a data visualization technique used to **estimate the probability density function** of a continuous variable. It provides a smooth representation of the distribution of a dataset, helping to visualize the underlying distribution shape, central tendency, and variability of the data.\n",
    "\n",
    "\n",
    "\n",
    "* **X-Axis**: Represents the variable being analyzed (e.g., values of a dataset).\n",
    "* **Y-Axis**: Represents the estimated density of the data at each point along the x-axis.\n",
    "* **Curve**: The smoothed curve that represents the estimated density function.\n",
    "\n",
    "**Comparison with Histograms**\n",
    "* **Smoothing**: Density plots provide a smoother visualization compared to histograms, which can appear jagged depending on the choice of bin size.\n",
    "* **No Binning**: Density plots do not require binning, which means they can represent data more accurately without arbitrary choices affecting the representation.\n",
    "* **Area Under the Curve**: The total area under a density plot equals 1, whereas the total area of a histogram is proportional to the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to plot the density curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data = dataset['pressure'], color='blue',  label='Weekday', fill=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(dataset['pressure'], kind='kde')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Plots \n",
    "# dataframe columns are not allowed in this chart\n",
    "\n",
    "\n",
    "density = dataset.iloc[:,1:].plot(kind='kde', x=4, subplots=True, legend=True, layout=(3, 4), figsize=(17, 12), sharex=False,\n",
    "                        fontsize=8, stacked=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz1CsnAyyxgP"
   },
   "source": [
    "# Boxplots\n",
    "\n",
    "A boxplot, also known as a box-and-whisker plot, is a standardized way of displaying the distribution of a dataset based on five summary statistics:\n",
    "\n",
    "* Minimum: The smallest data point, excluding outliers.\n",
    "* First Quartile (Q1): The median of the lower half of the dataset (25th percentile).\n",
    "* Median (Q2): The middle value of the dataset (50th percentile).\n",
    "* Third Quartile (Q3): The median of the upper half of the dataset (75th percentile).\n",
    "* Maximum: The largest data point, excluding outliers.\n",
    "\n",
    "\n",
    "**Components of a Boxplot**\n",
    "\n",
    "* **Box**: The box represents the interquartile range (IQR), which contains the middle 50% of the data (from Q1 to Q3). The length of the box indicates the degree of dispersion in the central half of the dataset.\n",
    "* **Median Line**:A line inside the box marks the median (Q2). This line indicates where the middle of the data lies.\n",
    "* **Whiskers**:The whiskers extend from the box to the minimum and maximum values within 1.5 times the IQR from the first and third quartiles. They provide a visual indication of variability outside the upper and lower quartiles.\n",
    "* **Outliers**: Points that fall outside of the whiskers are considered outliers and are often represented as individual points. They indicate values that are significantly lower or higher than the rest of the data.\n",
    "\n",
    "\n",
    "* The factor of 1.5 is a standard convention established in statistical literature. The 1.5 factor has been found empirically to work well across various types of data distributions. \n",
    "\n",
    "\n",
    " <img src=\"Figures/boxplot_explained.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <img src=\"Figures/Box-Plot-and-Whisker-Plot-2.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create boxplot for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qatjOCCPyxgP"
   },
   "outputs": [],
   "source": [
    "atributos_boxplot = dataset.plot(kind='box', subplots=True, layout=(4, 3), figsize=(11, 11),\n",
    "                                 sharex=False, sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's delete the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IQR Method:**\n",
    "\n",
    "* The first quartile (Q1) and the third quartile (Q3) are calculated.\n",
    "The IQR is computed as IQR = Q3-Q1 \n",
    "\n",
    "* Outliers are defined as values below Q1 - 1.5·IQR or above  Q3 - 1.5·IQR \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method\n",
    "\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "\n",
    "df_no_outliers_iqr = remove_outliers_iqr(dataset, 'pressure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = df_no_outliers_iqr.plot(kind='box', subplots=True, layout=(4, 3), figsize=(11, 11),\n",
    "                                 sharex=False, sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Z-Score Method:**\n",
    "\n",
    "* The Z-score for each value in the specified column is calculated.\n",
    "* Values with a Z-score greater than 3 or less than -3 are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean = dataset['radiation'].mean()\n",
    "st_dev = dataset['radiation'].std()\n",
    "dataset['radiation'].plot.hist(bins=20)\n",
    "plt.axvline(mean, color = 'Black', label = 'Mean')\n",
    "plt.axvline(mean - st_dev, color = 'Red', label = '-1σ')\n",
    "plt.axvline(mean + st_dev, color = 'Violet', label = '+1σ')\n",
    "plt.axvline(mean - 2*st_dev, color = 'Red', label = '-2σ')\n",
    "plt.axvline(mean + 2*st_dev, color = 'Violet', label = '+2σ')\n",
    "plt.axvline(mean - 3*st_dev, color = 'Red', label = '-3σ')\n",
    "plt.axvline(mean + 3*st_dev, color = 'Violet', label = '+3σ')\n",
    "plt.xlabel('Energy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "def remove_outliers_zscore(data, column):\n",
    "    z_scores = zscore(data[column])\n",
    "    print(z_scores)\n",
    "    return data[(z_scores > -3) & (z_scores < 3)]\n",
    "\n",
    "# there are some missing data we need to delete\n",
    "dataset_clean = dataset.dropna()\n",
    "df_no_outliers_zscore = remove_outliers_zscore(dataset_clean, 'radiation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = df_no_outliers_zscore.plot(kind='box', subplots=True, layout=(4, 3), figsize=(11, 11),\n",
    "                                 sharex=False, sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate plots\n",
    "\n",
    "\n",
    "<img src=\"Figures/step1-understand-data-2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion matrix\n",
    "\n",
    "A dispersion matrix, also referred to as a scatter matrix, is a collection of scatter plots arranged in a grid format where each variable in a dataset is plotted against every other variable. It helps visualize the pairwise relationships between multiple features in a dataset and is often used for exploratory data analysis.\n",
    "\n",
    "Why is it useful? It helps tp:\n",
    "* Detect correlations between variables.\n",
    "* Identify trends, patterns, or clusters in the data.\n",
    "* Spot outliers or non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html\n",
    "\n",
    "\n",
    "scatter_matrix(dataset, alpha=0.2, figsize=(14, 14), diagonal='kde', range_padding=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pair plot (scatter matrix)\n",
    "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "\n",
    "sns.pairplot(dataset, corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW7epHONyxgQ"
   },
   "source": [
    "## **Correlation matrix** \n",
    "\n",
    "A correlation matrix is a table that displays the pairwise correlation coefficients between multiple variables. Each cell in the matrix represents the correlation between two variables, with values ranging from -1 to +1.\n",
    "\n",
    "\n",
    "* **+1** indicates a **perfect positive correlation**: as one variable increases, the other also increases proportionally.\n",
    "* **0** indicates **no correlation**: changes in one variable do not predict changes in the other.\n",
    "* **-1** indicates a **perfect negative correlation**: as one variable increases, the other decreases proportionally.\n",
    "\n",
    "The diagonal of the matrix always contains ones (1) because each variable is perfectly correlated with itself.\n",
    "\n",
    "\n",
    "<img src=\"Figures/correlation.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "* **Pearson** correlation measures the **linear relationship** between two continuous variables\n",
    "* **Spearman** correlation assesses the **monotonic relationship** between two continuous variables.\n",
    "* Spearman’s Rank Correlation is ideal for data that isn’t normally distributed or lacks a linear relationship.\n",
    "* The choice between Spearman and Pearson depends on your data and research question.\n",
    "* Correlation does not imply causation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0UaipW4yxgQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculation of correlation coefficients\n",
    "corr = dataset.iloc[:,1:].corr(method='spearman')  # method{‘pearson’, ‘kendall’, ‘spearman’} \n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(16, 14))\n",
    "#Generar Heat Map,\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", mask=mask, vmin=-1, vmax=1)\n",
    "    # xticks\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    # yticks\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    # plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ccffcc; padding:10px; border-radius:5px;\">\n",
    "\n",
    "### <span style=\"color:blue\">Exercise 2</span>\n",
    "\n",
    "Use the pearson method. Does the correlation matrix changed a lot?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ccffcc; padding:10px; border-radius:5px;\">\n",
    "\n",
    "### <span style=\"color:blue\">Exercise 3</span>\n",
    "\n",
    "+ Which features are not relevant for PV generation forecast?\n",
    "+ Delete them\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThiCNDExyxgQ"
   },
   "source": [
    "## *Step 2: Prepare dataset*\n",
    "\n",
    "Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <img src=\"Figures/step1-understand-data-3.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`missingno ` Missing data visualization. Library to see where the missing data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install missingno\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "# Visualize missing data with missingno\n",
    "msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO3bJLddyxgQ"
   },
   "source": [
    "\n",
    "Check if Nan exists in the input data. \n",
    "\n",
    "- The [fillna] method of Pandas is used.\n",
    "- More information about how to impute values with [Scikit Learn].\n",
    "- Other methods can be used for imputation: interpolation, AI libraries to impute values, mean, median, etc. \n",
    "\n",
    "[Scikit Learn]: https://scikit-learn.org/stable/modules/impute.html\n",
    "[fillna]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.fillna()` of Pandas is used\n",
    "\n",
    "* ffill: propagate last valid observation forward to next valid.\n",
    "* backfill / bfill: use next valid observation to fill gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHVtwKaKyxgQ"
   },
   "outputs": [],
   "source": [
    "dataset_imputate = dataset.fillna(method=\"backfill\")\n",
    "dataset_imputate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6B0iw-iyxgQ"
   },
   "source": [
    "Comprobamos de nuevo que no existe ningún **Nan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPtjUIS-yxgR"
   },
   "outputs": [],
   "source": [
    "# Comprobar si falta algún dato y en qué atributo\n",
    "dataset_imputate.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total missing data: ', dataset.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rows deletion**\n",
    "\n",
    "Use `.dopna()` method. \n",
    "\n",
    "`DataFrame.dropna(*, axis=0, how=<no_default>, thresh=<no_default>, subset=None, inplace=False, ignore_index=False)[source]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rows_deletion = dataset.dropna()\n",
    "dataset_rows_deletion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si falta algún dato y en qué atributo\n",
    "dataset_rows_deletion.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas Profiling: Tool to generates an exploratory analysis of the dataset in use. When executed, an HTML report is generated with:\n",
    "* Quantile statistics\n",
    "* Descriptive statistics\n",
    "* Most frequent values\n",
    "* Histograms\n",
    "* Correlations\n",
    "* Missing values\n",
    "   \n",
    "   Among others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ydata_profiling\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply ProfileReport\n",
    "\n",
    "london = pd.read_csv('Data/block_13_diario.csv')\n",
    "profile = ProfileReport(london, title='Profile Report')\n",
    "profile.to_file(\"your_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/sbarja/introduccion_machinelearning/blob/main/EJ1-regresion-PV.ipynb",
     "timestamp": 1681815192896
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
