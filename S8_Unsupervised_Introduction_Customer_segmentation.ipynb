{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; font-weight: bold; margin-top: 25px;\">\n",
    "\n",
    "# Introduction to Unsupervised Learning: customer segmentation\n",
    "    \n",
    "</div>\n",
    "\n",
    "> Example to explain the concept of customer segmentation\n",
    ">\n",
    "> **Objective:** You are the owner of a shopping center and want to understand the behavior of your customers in order to give this information to the marketing team and plan the strategy accordingly.\n",
    "\n",
    "> * For this example, Hierarchical and K-means clustering methods are used. \n",
    "> * Also, dimensionality reduction is used to plot the data in 2D dimension plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import data\n",
    "df=pd.read_csv(\"Data/Mall_Customers.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Gender is an Object type. We will need to transform the string feature into discrete numerical values. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; font-weight: bold; margin-top: 25px;\">\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "    \n",
    "</div>\n",
    "\n",
    "> Gender distribution \n",
    "> \n",
    "> Gender distribution by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "\n",
    "import seaborn as sns\n",
    "sns.countplot(x='Gender', data=df)\n",
    "plt.title('Distribution of Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    " Gender distribution by age\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.hist('Age', data=df[df['Gender'] == 'Male'], alpha=0.2, color='g', label='Male')\n",
    "plt.hist('Age', data=df[df['Gender'] == 'Female'], alpha=0.2, color='blue',label='Female')\n",
    "plt.title('Age distribution by gender')\n",
    "plt.xlabel('Age')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    " Age distribution by gender\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(data=df[df['Gender'] == 'Male']['Age'], \n",
    "            fill=True, color='green', label='Male', alpha=0.3)\n",
    "sns.kdeplot(data=df[df['Gender'] == 'Female']['Age'], \n",
    "            fill=True, color='blue', label='Female', alpha=0.3)\n",
    "\n",
    "# Add a descriptive title and axis labels\n",
    "plt.title('Age Distribution by Gender (Density Plot)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Gender\", fontsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    " Boxplot Age - Gender\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(x=\"Gender\", y=\"Age\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Bonxplot with 'Annual Income(k$)'\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(x=\"Gender\", y=\"Annual Income (k$)\", data=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Boxplot with 'Spending Score (1-100)'\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(x=\"Gender\", y=\"Spending Score (1-100)\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Variables correlation\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check variables correlation\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Error! We have string data in our Dataframe. \n",
    "    \n",
    "</div>\n",
    "\n",
    "> * If the model you're using doesn't assume an ordinal relationship (like most modern ML models), use **One-Hot Encoding**.\n",
    ">\n",
    "> * If dimensionality is a concern or you're using algorithms like decision trees that are robust to ordinal values, **Label Encoding** is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Gender'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check variables correlation\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "## Example 1. Hierarchical Clustering: groups of clients which are similar regarding Annual Income vs. Age\n",
    "    \n",
    "</div>\n",
    "\n",
    "> * **Agglomerative Clustering** is a type of hierarchical clustering algorithm used to group similar data points together. It is a bottom-up approach, where each data point starts as its own individual cluster, and pairs of clusters are merged as we move up the hierarchy.\n",
    "\n",
    "> Bottom-up Approach:\n",
    "            > * Initially, each data point is treated as its own cluster.\n",
    "            > * The algorithm iteratively merges the two closest clusters at each step.\n",
    "            > * This process continues until all data points are merged into a single cluster or until a predefined number of clusters is reached.\n",
    "\n",
    "> ``AgglomerativeClustering(n_clusters=5)``: Hierarchical clustering is performed, and the n_clusters argument specifies the number of clusters you want to identify. You can modify this number based on your analysis or the dendrogram.\n",
    "\n",
    "> ``fit_predict()``: This method fits the model to the scaled data and assigns each data point to a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a subset/specific dataframe for this exercise\n",
    "df_age_income = df[['Age', 'Annual Income (k$)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Scale the data and Apply Agglomerative clustering\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Step 1: Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_age_income_scaled = scaler.fit_transform(df_age_income)\n",
    "\n",
    "# Step 2: Apply Agglomerative Clustering (Hierarchical Clustering)\n",
    "agg_clustering = AgglomerativeClustering()  # You can adjust the number of clusters as needed -- n_clusters=2\n",
    "y_hierarchical = agg_clustering.fit_predict(df_age_income_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_age_income_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 3: Plot the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_age_income_scaled[:, 0], df_age_income_scaled[:, 1], c=y_hierarchical, cmap='viridis', s=50)\n",
    "plt.title('Hierarchical Clustering')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Annual Income (k$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Plot the results with non-scale data to understand better the groups\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Plot the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_age_income.loc[:, \"Age\"], df_age_income.loc[:, \"Annual Income (k$)\"], c=y_hierarchical, cmap='viridis', s=50)\n",
    "plt.title('Hierarchical Clustering')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Annual Income (k$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Visualizing the Dendrogram\n",
    "    \n",
    "</div>\n",
    "\n",
    "> The dendrogram helps to visualize how clusters are merged at each level, and the vertical distance between branches indicates how similar the clusters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Step 4: Create the linkage matrix for the dendrogram\n",
    "linked = linkage(df_age_income, 'ward')\n",
    "\n",
    "# Step 5: Plot the dendrogram\n",
    "plt.figure(figsize=(20, 7))\n",
    "dendrogram(linked)\n",
    "plt.title('Dendrogram for Hierarchical Clustering')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Euclidean Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "## Example 2. K-means: Find K groups of clients which are similar regarding Spending Score vs. Age\n",
    "    \n",
    "</div>\n",
    "\n",
    "> * To set the number of clusters we want to have as a result, we will use the **Elbow method**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Age', y='Spending Score (1-100)', data=df)\n",
    "plt.title('Age to Spending Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; font-weight: bold; margin-top: 25px;\">\n",
    "\n",
    "Elbow method\n",
    "    \n",
    "</div>\n",
    "\n",
    "> * The Elbow Method is a commonly used technique in clustering analysis to determine the optimal number of clusters (k) in a dataset.\n",
    "> * On the graph, the **x-axis** represents the **number of clusters (k)**, and the **y-axis** represents the within-cluster sum of squared errors **(WCSS)**.\n",
    "> * The Elbow Method helps balance between:\n",
    "    * Underfitting: Too few clusters (large WSS).\n",
    "    * Overfitting: Too many clusters (small WSS but with less meaningful groupings).\n",
    "> * By choosing the \"elbow point,\" you aim for a model that captures the structure of the data efficiently without unnecessary complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "Scale the data\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a subset/specific dataframe for this exercise\n",
    "df_age_spending = df[['Age', 'Spending Score (1-100)']]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_age_spending_scaled = scaler.fit_transform(df_age_spending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_spending_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "wcss = []\n",
    "K = range(1,15)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(df_age_spending_scaled)\n",
    "    wcss.append(km.inertia_)\n",
    "plt.plot(K, wcss, 'bx-')\n",
    "plt.xlabel('Number of centroids')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * The elbow appears to occur at **k = 3**. After this point, the WCSS starts to decrease at a much slower rate, indicating that adding more clusters doesn't significantly improve the model's fit. Therefore, k = 3 is likely the optimal number of clusters for this dataset.\n",
    "\n",
    "> * ``fit()``: Fits the k-means model to the data. This means that the k-means algorithm calculates the positions of the cluster centroids and assigns them to the data instances based on these positions.\n",
    "> * ``predict()``: Assigns each data point to one of the clusters already calculated by the model. In other words, after the centroids of the clusters are calculated, the algorithm assigns each point to its closest centroid.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_age_spending_scaled)\n",
    "y_kmeans = kmeans.predict(df_age_spending_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(df['Age'], df['Spending Score (1-100)'], c=y_kmeans, s=50, alpha=0.5,cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spending Score (1-100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "Marketing target group could be as follows:\n",
    "\n",
    "> * Group of young people with high spending.\n",
    "> * Group of young people with low spending.\n",
    "> * Older group of people with low and medium spend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "## Example 3. K-means: Find K groups of clients which are similar regarding Spending Score vs Annual Income\n",
    "    \n",
    "</div>\n",
    "\n",
    "> * To set the number of clusters we want to have as a result, we will use the **Elbow method**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which groups do you detect?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', data=df)\n",
    "plt.title('Annual Income(k$) to Spending Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset/specific dataframe for this exercise\n",
    "df_income_spending = df[['Annual Income (k$)', 'Spending Score (1-100)']]\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_income_spending_scaled = scaler.fit_transform(df_income_spending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "wcss = []\n",
    "K = range(1,15)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(df_income_spending_scaled)\n",
    "    wcss.append(km.inertia_)\n",
    "    \n",
    "\n",
    "\n",
    "# Plot the Elbow\n",
    "plt.plot(K, wcss, 'bx-')\n",
    "plt.xlabel('Number of centroids')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(df_income_spending_scaled)\n",
    "y_kmeans = kmeans.predict(df_income_spending_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(df['Annual Income (k$)'], df['Spending Score (1-100)'], c=y_kmeans, s=50, alpha=0.5,cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "> * Low income, high spending (Yellow cluster): These customers have low incomes but spend heavily, indicating strong engagement or discretionary spending habits.\n",
    "> * Low income, low spending (Green cluster): Customers in this group have low incomes and spend minimally, likely budget-conscious shoppers.\n",
    "> * Moderate income, moderate spending (Purple cluster): These customers have moderate incomes and spend moderately, likely representing the store’s core, regular customer base.\n",
    "> * High income, low spending (dark blue cluster): Despite having high incomes, these customers spend less. The store may need to find ways to increase engagement or tailor marketing efforts for this group.\n",
    "> * High income, high spending (Blue cluster): Have high incomes and spend heavily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    "#  Dimensionality reduction with linear unsupervised method, Principal Component Analysis (PCA) \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Principal Component Analysis (PCA) is a statistical technique used for dimensionality reduction. It transforms a high-dimensional dataset into a lower-dimensional one by identifying the most important directions (called principal components) that capture the maximum variance in the data. This allows for a more efficient representation of the data while preserving its essential structure, making it easier to visualize and analyze.\n",
    "> * In simpler terms, PCA reduces the number of variables in the data while retaining as much information as possible.\n",
    "\n",
    "\n",
    ">\n",
    "> * We use the overall dataset to cluster clients, considering all the information given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"CustomerID\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction: PCA\n",
    "\n",
    "> * Reduce the dataset to 2 principal components that capture the maximum information of the original attributes.\n",
    "> * By applying PCA, we transform the data into a 2D space, allowing us to visually observe the structure and grouping of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)  # Scaling the data\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "results_pca = pca.fit_transform(df)\n",
    "print(results_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(results_pca[:, 0], results_pca[:, 1],alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate for this 2 features, the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "K = range(1,15)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(results_pca)\n",
    "    wcss.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K, wcss, 'bx-')\n",
    "plt.xlabel('Number of centroids')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(results_pca)\n",
    "y_kmeans = kmeans.predict(results_pca)\n",
    "\n",
    "plt.scatter(results_pca[:, 0], results_pca[:, 1], c=y_kmeans, s=50, alpha=0.5,cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the resulting Clusters to the Original Data\n",
    "\n",
    "> * **Clustering results in labels**: Through the clustering process, we have generated labels for each data point.\n",
    "> * **Supervised learning with cluster labels**: These labels can now be used to train a supervised classification model. Unsupervised methods like clustering are essential for creating labels.\n",
    ">  * **Predicting customer groups**: When a new customer arrives, we can predict which group they belong to based on their input data, without needing any prior study or manual grouping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.copy()\n",
    "df_labels['cluster'] = y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    " ## Plot Age vs Annual Income, coloring the data points for each Cluster\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot with color depending on the 'cluster' column\n",
    "sns.scatterplot(data=df_labels, x='Age', y='Annual Income (k$)', hue='cluster', palette='viridis', s=100)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Age vs Annual Income by Cluster')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Annual Income (k$)')\n",
    "plt.legend(title='Cluster', loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    " ## Plot Annual Income (k$) vs Spending Score, coloring the data points for each Cluster\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot with color depending on the 'cluster' column\n",
    "sns.scatterplot(data=df_labels, y='Spending Score (1-100)', x='Annual Income (k$)', hue='cluster', palette='viridis', s=100)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Annual Income (k$) vs Spending Score by Cluster')\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.legend(title='Cluster', loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 25px; border-radius: 5px; margin-top: 25px;\">\n",
    "\n",
    " ## Plot Age vs Spending Score, coloring the data points for each Cluster\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot with color depending on the 'cluster' column\n",
    "sns.scatterplot(data=df_labels, y='Spending Score (1-100)', x='Age', hue='cluster', palette='viridis', s=100)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Age vs Spending Score by Cluster')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.legend(title='Cluster', loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
