{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unsupervised learning example: Clustering daily consumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In unsupervised learning, the classic task is **cluster analysis** in which hidden patterns or groups are found in the data. Most of the time unsupervised learning tasks have an *open solution*, so you have to interpret the results and check if they make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:** This example uses data containing information about the annual electricity consumption of a household in Austin, USA. The objective is to find the optimal number of clusters to group the different daily consumption patterns of the household throughout the year. The data contains multiple households, so one must be selected (id=9922)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context:** This example presents an unsupervised learning problem in which different clustering algorithms and evaluation metrics are used and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we start:\n",
    "\n",
    "* The file **15minute_data_austin_.csv** contains the input dataset for this example (attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import libraries and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libreries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# To suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Select needed columns\n",
    "columns_to_use = ['dataid', 'local_15min', 'grid']\n",
    "df_activepower = pd.read_csv('Data/data_austin.csv', sep=';', usecols=columns_to_use)\n",
    "df_activepower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Understanding the data**\n",
    "\n",
    "It is necessary to visualize and understand the data we are going to work with, as well as to know its characteristics.\n",
    "\n",
    "1. How much data is there? How many attributes are there in the data?  \n",
    "2. What do they mean?\n",
    "3. Is there any missing data?\n",
    "4. Statistical summary of the input data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of input data (rows x columns)\n",
    "df_activepower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the data looks like\n",
    "df_activepower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activepower.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What do they mean?** \n",
    "\n",
    "* **[Dataid]**: numeric identification of each household\n",
    "* **[local_15min]**: date and time format\n",
    "* **[grid]**:  power consumed in each period [kW]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the household with id = 9922 for this example\n",
    "df_household = df_activepower.loc[df_activepower['dataid'] == 9922]\n",
    "\n",
    "# Transform local_15min to datetime format with .to_datetime()\n",
    "df_household['datetime'] = pd.to_datetime(df_household['local_15min'], format='%d/%m/%Y %H:%M')\n",
    "print(df_household)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household.dtypes\n",
    "df_household.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove household dataid and local_15min column\n",
    "df_household = df_household.drop(['dataid', 'local_15min'], axis=1)\n",
    "df_household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column 'datetime' to index.\n",
    "df_household = df_household.set_index('datetime')\n",
    "df_household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the new row x column data dimensions\n",
    "df_household.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there is any categorical data to be transformed\n",
    "df_household.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Is any data missing?** A check is made to see if any data is missing, and then empty cells are counted.\n",
    "In this case, no data is missing in the input data set (there are no *Nan* values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Summary statistics of the input data set:** Descriptive statistics collects and analyzes the input data set with the objective of describing the characteristics and behaviors of this set through the following summary measures: total number of observations (count), mean (mean), standard deviation (std), minimum value (min), maximum value (max) and the values of the different quartiles (25%, 50%, 75%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the nature of the data with descriptive statistics.\n",
    "df_household.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualize the data**\n",
    "\n",
    "A visual way to understand the input data. \n",
    "1. Histogram\n",
    "2. Density curve\n",
    "3. Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Histogram**\n",
    "\n",
    "Graphical representation of each of the attributes in the form of bars, where the surface of the bar is proportional to the frequency of the values represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = df_household.hist(xlabelsize=10, ylabelsize=10, bins=300, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Density graph**\n",
    "\n",
    "Visualize the distribution of the data. It is a variable of the histogram, but eliminates noise, so they are better for determining the distribution shape of an attribute. Density plot spikes help show where values are most concentrated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = df_household.plot(kind='kde', legend=True, layout=(1, 1), figsize=(10, 10),\n",
    "                        fontsize=16, stacked=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Boxplots** \n",
    "\n",
    "The boxplot allows us to identify outliers and compare distributions. In addition, we know how 50% of the values are distributed (inside the box). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=df_household[\"grid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4. Prepare the data*\n",
    "\n",
    "1. Data cleaning and restructuring\n",
    "2. Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data to obtain the average hourly power. Each row will represent 1h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household_hourly = df_household.resample('H').mean()\n",
    "df_household_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the hour\n",
    "df_household_hourly['hour'] = df_household_hourly.index.hour\n",
    "df_household_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new index now contains only the date (DD/MM/YYYYYY).\n",
    "df_household_hourly.index = df_household_hourly.index.date\n",
    "df_household_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with the average power of each hour \n",
    "df_household_pivot = df_household_hourly.pivot(columns='hour')\n",
    "df_household_pivot = df_household_pivot.dropna()\n",
    "\n",
    "df_household_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the transformed data\n",
    "Each line shows the hourly consumption for one day of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly consumption. Dataframe has to be transposed.\n",
    "df_household_pivot.T.plot(figsize=(18, 8), title='Daily Consumption', legend=False, color='blue', alpha=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Transformation**. \n",
    "\n",
    "The data is scaled using the *MinMaxScaler()* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = df_household_pivot.values.copy()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unsupervised Learning Model Building: Data Clustering using K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are grouped using the algorithm [K-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and evaluation metrics [silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html). The K-means algorithm needs to be told the number of clusters into which you want to group the data. You run the algorithm for several clusters and then compare the results using the silhouette_score metric, which will indicate the optimal number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal number of clusters: Silhouette Coefficient\n",
    "The Silhouette Coefficient is used, where the best value is 1 and the worst value is -1. Values close to 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, since a different cluster is more similar. Check documentation here: [sklearn.metrics.silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "# Evaluate the K-means algorithm for a range of [2,15] clusters. \n",
    "n_cluster_list = np.arange(2, 16).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration to evaluate K-means for different number of clusters (n_clusters)\n",
    "for n_cluster in n_cluster_list:\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=0)\n",
    "    cluster_found = kmeans.fit_predict(X_scaled)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_metric = pd.DataFrame(index=n_cluster_list, columns=['silhouette_score'], data=silhouette_scores)\n",
    "plt.plot(silhouette_metric, marker='o') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the K-means for the optimal number of clusters given the result of the Silhouette method.\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters= , random_state=1990)  # write here the optimal number of clusters\n",
    "cluster_found = kmeans.fit_predict(X_scaled)\n",
    "cluster_found_sr = pd.Series(cluster_found, name='cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a multindex of the type: (date,cluster to which the day belongs)\n",
    "df_household_pivot_clusters = df_household_pivot.set_index(cluster_found_sr, append=True)\n",
    "df_household_pivot_clusters.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household_pivot_clusters.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14,5))\n",
    "color_list = ['blue',  'red']\n",
    "cluster_values = sorted(df_household_pivot_clusters.index.get_level_values('cluster').unique())\n",
    "print(cluster_values)\n",
    "\n",
    "for cluster, color in zip(cluster_values, color_list):\n",
    "    # plot every line of both clusters\n",
    "    df_household_pivot_clusters.xs(cluster, level=1).T.plot(ax=ax, legend=False, alpha=0.05, color=color)\n",
    "    # plot the mean consumption of each cluster\n",
    "    df_household_pivot_clusters.xs(cluster, level=1).mean().plot(ax=ax, color=color, legend=False, alpha=0.8, ls='--')\n",
    "\n",
    "ax.set_ylabel('Average hourly power [kW]')\n",
    "ax.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means has found the clusters with the following characteristics, looking at the graph above:\n",
    "* One of the clusters concentrates the highest consumption patterns with the highest consumption peaks.\n",
    "* The other concentrates a lower average hourly power consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating results with Dimensionality Reduction (PCA)\n",
    "Principal Component Analysis (PCA) is a statistical method that simplifies the complexity of sample spaces with many dimensions while preserving their information. The number of features is reduced from 24 to 2. \n",
    "One way to validate the results of the clustering algorithm is by dimensionality reduction techniques. Note that the PCA does not know anything about the groups found by K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.colors\n",
    "\n",
    "pca = PCA(n_components=2, random_state=1990)\n",
    "results_pca = pca.fit_transform(X_scaled)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(cluster_values, color_list)\n",
    "\n",
    "plt.scatter(results_pca[:, 0], results_pca[:, 1],\n",
    "            c=df_household_pivot_clusters.index.get_level_values('cluster'),\n",
    "            cmap=cmap,\n",
    "            alpha=0.4,\n",
    "            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph above, each point represents a daily consumption profile. Theoretically, the distance between the points in the dimensional space is maintained, so points that are close together have similar daily consumption profiles.\n",
    "\n",
    "The fact that most of the blue and red points are close together is a good indication that the clustering is correct. The results of the K-means algorithm are used to color the points in order to evaluate the performance of the K-means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Try the Elbow method and see if it is similar.\n",
    "Elbow Method [example](https://localcoder.org/scikit-learn-k-means-elbow-criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the same scaled dataset for comparing the Silouethe with the Elbow method\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
